Microservices   
    It’s an approach to achieving loose coupling by creating multiple independent components, each with its own process. This enhances agility, scalability, usability, and enables parallel development. While making complex to built and achieve security.

MONOLITHIC V/S MICROSERVICES    :
            Parallel development    -
                Dev team can work independently on different componenets witout blocking development of other each other.
                
                In monolithic, it is hard to achieve compared to microservices.
                    - Tight coupling
                        - The same code base is shared in the application, and changing that might break other parts of the system.
                    - Limited tech choices:
                        - In monolithic, the same tech stack has to be used for the whole application.
                        - In microservices, each team can pick the best/optimized tech stack as per requirement.
                    - Testing:
                        - The whole application needs to be tested, which is time-consuming.
                    - Deployment:
                        - The whole application needs to be packaged and re-deployed.    
            
            Agility -
                It is ability to adapt changes quickly in terms of speed and responsiveness.
                
                In monolithic, components are thight couple compated to microservices which make it less agile.
                    - Any change in monolithic app can impact entire app which makes longer development, testing and deployment.
                    - Any change in microservices can impact independent service which makes it loose coupling and faster software development cycle.

            Scalibility -
                Ability to handle newly added resources without impacting performance. Resource can be traffic (new users and new data).

                In monolithic, if Order component gets more traffic then we need to scale whole application. In result, less used components such as Review component are created Which leads to more waste of resource and incresed costs. 

                In microservices, if order component gets more traffic we can only increse scale of that component. It is more efficient and cost-effective

            Usability   -
                How easily a system can be used, extended and maintained -- both from development and user experience perspective.

                Microservices have more edge because they are easier to maintain and scale.

            Complexity  -
                Microservices are more complex to create as it require more planning and infrastructure. Microservices have more issues/errors related to latency adn failure between services.

            Security    -
                Monolithics are easy to secure because of single entry point, simple data access and single point of failure.
                Microservices on other hand have multiple entry points and each entry points needs to be secure and handled each issue/error. Also, they've differenet data base which create data isolcation.

Why SpringBoot better to use for microservices?
            Springboot provides full range of built in features, integration and starter project. ex, dependency injection, auto-configuration etc.
            It also provides built in servers like Tomcat, Jetty during development.
            Additionally, production-ready features health check, admin etc.
            Last but not least, smooth cloud integration and containerization.

YAML V/S properties file:
            YAML file is lightweight and easy to read.
            Mainly used for configuration and automation.
            YAML is used for springboot configuration, Docker, Kubernets, CI/CD pipeline etc.

            properties file:
                // application.properties
                    server.port=8080
                    spring.datasource.url=jdbc:h2:mem:testdb
                    spring.datasource.username=sa
                    spring.datasource.password=password    
                    app.user[0]=Krunal
                    app.user[1]=kruz

            yml file:
                // application.yml
                    server:
                        port: 8080
                        datasource:
                            url: jdbc:h2:mem:testdb
                            username: sa
                            password: password
                    app:
                        user:
                            -Krunal
                            -kruz

Implement REST services:
            REST service entry points
                CRUD operations
                    Create  ->  HttpMethod.POST
                    Read    ->  HttpMethod.GET
                    Delete  ->  HttpMethod.DELETE
                    Update  ->  HttpMethod.PATCH/PUT
            Error/Exception handling   
            Document Rest services

DTO (Data Transfer Object)  :
            DTOs are used to fetch only required data instead of fetching entire entity object.

            Advantages of DTOs:
                ->  Encapsulate Entity   ::  
                        DTOs decouple the database layer from the API layer, preventing direct exposure of entity models.
                        Here, DTOs hide sensitive data such as Id, password from client application. 
                        DTOs do not update entity object.
                ->  Performance ::
                        DTOs send only required fields which reduce overall payload of server.
                        DTOs combine data from multiple entities and send single response object.
                ->  Security    ::
                        DTOs allow custom validations before processing request.
                        DTOs hide/filter sensitive information while sending response to presentation layer.

Response V/S ResponseEntity :
            Response will send only data retrieved from data access layer.
            Response entity will not only have response but also error code, error message and body.

Create REST webApplication:
            Step 1
                Add dependency to create webApp.
                    Spring Web  -
                                It provides built in core features for building web/RESTful applications.
                    H2 Database -
                                For testing/PoC spring project, To server based memory database H2DATABASE is used.
                    Spring Data JPA -
                                To interact with databases by using Java objects and an abstraction over CRUD operations.
                    Spring Boot Actuator    -
                                Provides built in endpoints to monitor health and metrics over memory usage, http request, CPU load etc.
                    Spring Boot DevTools    -
                                Re-Start application much faster for better dev experience.
                    lombok  -
                                Built in annotation to automatically generate Getter, Setter, constructor and toString() method.
                    Validation  -
                                Bean validation.

            Step 2
                Create EndPoint and access it.
                    // accountController.java
                    @RestController
                    public class accountController {

                        @GetMapping("hi")
                        public String welcome(){
                            return "Hello Krunal! <br/>This is your application. Enjoy!";
                        }
                    }
                Access endpoint by http://localhost:8080/hi address

            Step 3
                Create H2DATABASE and table inside:

                Step 3.1
                    Configure H2 in application.yml        
                        # application will run on port number 8080.
                        server:
                            port: 8080

                        # jdbc h2 setting up username, password and url
                        spring:
                            datasource:
                                url:  jdbc:h2:mem:testdb        #   testdb will be created in server memory.
                                username: sa                    #   default h2database id/password.
                                password: ''
                            
                        # setting up H2's web based console:
                        spring:
                            h2:
                                console:
                                    enabled: true               #   With enable console, dev can open web-based H2-console and execute SQL query.
                                                                #   If H2-console is disable, dev can't open it. Only way to validate query is through operation or log in application.

                        # Dialect which will act as translator to communicate between spring application and h2database.
                        spring:
                            jpa:
                                driverClassName: org.h2.Driver  #   H2 Driver will be used as translator between application and h2 database. where translator knows how to handle request like connecting, querying and updateing data.
                                hibernate:
                                    ddl-auto: update            #   for development
                                show-sql: true                  #   show sql query on console during run-time

            Step 4
                Create DATABASE and Entity class:
                Step 4.1
                    Create Database in .sql file:
                        // schema.sql
                        CREATE TABLE IF NOT EXISTS `customer` ();
                        CREATE TABLE IF NOT EXISTS `accounts` ();
                Step 4.2
                    Entity class:
                        // Customer.java
                        @Entity
                        @Table(name = "customer")
                        @Getter @Setter @ToString @AllArgsConstructor @NoArgsConstructor
                        public class Customer extends BaseEntity{
                            @Id
                            private long customerId;

                            @Column(name = "name");
                            private String name;
                        }
                Step 4.3
                    JPA Repository:
                        // AccountRepository.java

validated on @pathVariable and @requestParams
valid on @RequestBody

audit ->
    baseEntity -> @CreatedBy @CreatedAt @LastModifiedBy @LastModifiedAt
    auditOrAware class  ->  override method AuditOrAware<String> and give component name to it.
    main file   ->  @EnableJpaAuditing(auditOrAwareRef = beanComponentNameFrmAoveStep) 

Swagger API -> for documentation...
    add dependency
    go to...
         localhost:8080/swagger-ui/index.html

    NOTE:
        make sure getter is available for schema/DTO/EntityClass

    For entityClass/ DTO:
        @Schema(
            name = "",
            description = ""
        )
        public class Table{
            
            @Schema(
                description =""
            )
            private String name;
        
        }

    For RestAPI controller:
        @Tag(
            name = "",
            description = ""
        )
        public class AccountContoller{
            @Operation(
                summary ="",
                description = ""
            )
            @APIREsponses({
                @ApiResponse(
                    responseCode = "",
                    description=""
                ),
                @ApiResponse(
                    responseCode = "",
                    description ="",
                    content = @Content(
                        schema = @Schema(implementation = .class)
                    )
                )
            })
        }

@RestController     -->     @Controller + @ResponseBody
new ResponseEntity<?>
RequestEntity<?>    |    @RequestBody   |    @requestHeader
@RequestParams

Strangler Fig pattern   ::
            It is an approach to replace monolithic application with Microservices. 
            A existing domain of monolethic application is being replced by an microservice once it is availble for production. 
            But 100% of traffic is not being moved directly but on some ration is moved for test and validation purposes. 
            Later one by one, components are being replaced by microservices.

Docker  ::
            Generate Docker image   :
                        DockerFile  -
                            Write layer of instructions.
                            Once build command is executing, this DockerFile is used to generate a docker image on a Docker Server.

                            NOTE:
                                If Layer of DockerFile is not changed, cache is being used by server.
                                If Layer of DockerFile is canged, all following layers will be executed.

                            Example :
                                    Step 1:
                                        packing can be done either in jar or war version.

                                        Add this line to POM.xml:
                                            <packaging>jar</packaging>

                                        Now, Let's compile application from scratch. And rebuild Jar files for CI/CD.

                                        Run commnad to clean and re-install all dependencies:
                                            mvn clean install 

                                            This command made of 2 commands.
                                            mvn clean   -   deletes target folder which contains all caches, complied files
                                            mvn install -   Install dependencies from POM.xml, compile code, run test classes, package application (jar file)

                                        Run application and Test it using Postman:
                                            Way 1 using Maven:
                                                To run application from console use mvn command:
                                                    mvn spring-boot:run

                                                    NOTE:
                                                        You need Maven to run this command so make sure it is installed to system.
                                                        In POM.xml file has maven plugin added to build. 
                                                        Else you can't run application from terminal.

                                            Way 2 using Java:
                                                Java command to run application from console:
                                                    syntex:
                                                        java -jar PATH_TO_FILE
                                                    
                                                    java -jar target/accounts-0.0.1-SNAPSHOT.jar

                                            Run all APIs from postman.

                                    Step 2:
                                        Generate Docker image:
                                            Create Dockerfile which is blueprint to create container. 
                                            It has layers and each layer has instruction in order to build container.

                                            We have to install all dependency and perform all steps before running application. 
                                            From installing java dependency, coping all jar files, and executing run command.

                                            Dockerfile:
                                                FROM openjdk:17-jdk-slim
                                                MAINTAINER easybytes.com
                                                COPY target/accounts-0.0.1-SNAPSHOT.jar accounts-0.0.1-SNAPSHOT.jar
                                                ENTRYPOINT ["java", "-jar", "accounts-0.0.1-SNAPSHOT.jar"]

                                            Run docker build command:
                                                syntex:
                                                    docker build . -t DOMAIN_NAME/SERVICE_NAME:VERSION

                                                    docker build . -t eazybytes/accounts:s4

                                            View Docker image by command:
                                                docker images

                                    Step 3:
                                        Generate Container:
                                            syntex:
                                                docker run -p 8080:8080 DOCKER_IMAGE_NAME

                                                docker run -p 8080:8080 eazybytes/accounts:s4

                                            Generate Container in detached mode so that you can access terminal to run other commands.
                                            syntex:
                                                docker run -d -p 8080:8080 DOCKER_IMAGE_NAME

                                                docker run -d -p 8080:8080 eazybytes/accounts:s4

                                            Go to Docker Desktop to view container to verify it is running. Or use postman to test apis.

                        BuildPack   :
                            Simplifies the process, we do not need to write a low-level dockerfile.

                            Step 1:
                                Add docker image name into POM.xml file.
                                    <plugin>
                                        <groupId>org.springframework.boot</groupId>
                                        <artifactId>spring-boot-maven-plugin</artifactId>
                                        <configuration>
                                            <image>
                                                <name>eazybytes/${project.artifactId}:s4</name>
                                            </image>
                                        </configuration>
                                    </plugin>

                            Step 2:
                                Generate docker image without dockerfile by using buildpacks:
                                    Run command:
                                        mvn spring-boot:build-image

                            Step 3:
                                Create docker container:
                                    docker run -d -p 8090:8090 DOCKER_IMAGE_NAME

                        Google Jib  :
                            Maintained by Google, For building Docker images of Java applications.
                            
                            Step 1:
                                Add plugin jib to POM.XML file:
                                    Go to website and copy the xml code.
                                    Make sure to give proper name to image.

                                Add <packaging>jar</packaging> to POM.xml file.
                            
                            Step 2:
                                Generate docker image:
                                    mvn compile jib:dockerBuild

                            Step 3:
                                Build docker container  
                                    docker run -d -p 9000:9000 DOCKER_IMAGE_NAME

            Commands::
                docker built . -t DOCKER_IMAGE_NAME         --> Creates docker image based on Docker file.
                docker run -p 8080:8080 DOCKER_IMAGE_NAME   --> Creates container based on Docker image.

                docker login
                docker image push krunal1k/accounts:s4
                docker image pull krunal1k/accounts:s4
                docker logout

                docker images           --> Shows list of Docker images
                docker search STRING    --> Shows matched named Docker images
                docker image rm [id]    --> Removes Docker image with given id.
                docker rmi [id]         --> Removes Docker image with given id.
                docker image prune      --> Removes all unused images. Which does not have container.

                docker ps       --> Shows running containers.
                docker ps -a    --> Shows all available containers (even with stopped status).
                docker rm [id]  --> Removes Docker containers of given id.
                docker system prune --> Removes unused Docker container. 

                docker container start [id]     --> 
                docker container stop [id]      -->
                docker contianer kill [id]      -->
                docker container pause [id]
                docker container unpause [id]

                docker container restart [id]
                
                docker container logs [id]

                docker compose up -d    --> To create containers out of docker images
                docker compose stop     --> To stop containers from executing requests
                docker compose start    --> To continue executing upcoming requests to container
                docker compose down     --> To delete containers 

Docker compose ::
            Instead of creating one by one, docker images and container for each microservice. Use Docker compose to create all containers.

            Create "docker-compose.yml" file:
            // This file will create Account-ms container but we already need image created inside docker to run application.
                services:
                    accounts:
                        image: "eazybytes/accounts:s4"
                        container_name: accounts-ms
                        ports:
                        - "8080:8080"
                        deploy:
                        resources:
                            limits:
                            memory: 700m
                        networks:
                        - eazybank
                networks:
                    eazybank:
                        driver: "bridge"

Port mapping/ Port forwarding/ Port publishing  :
            In docker, containers are in isloated network.
            We need access to external port to access this isloated network. 

            During "docker run -d -p 8081:8080 DOCKER_IMAGE_NAME", 
            we are creating container at 8080 port number which is isloated. 
            While 8081 port is external port from where user can access APIs and application features.

Cloud-native application    V/S     Native application  ::
            OS abstraction/ independent while natives are OS dependent.
            Resizing bacause of containerization but it is not possibel for native applications.
            CD (Continuous Delivery) while native application needs to be delivered using waterfall approach.
            Rapid recovery and automated scalability bacause of kubernative while native applications have slow recovery.

15 factor methodologies to build Cloud-native application  ::
            Codebase    --> Each microservice has its own codebase. Only configuration files are differenet from environment to environment.
            ├── Build Phase methodologies:
            │      ├── Dependencies --> All dependencies should be tracked in Pom.xml/ gradle file. Do not relay on OS or system package. 
            │      ├── Config   --> Config stored on env or external files. It should not be hard coded.
            │      ├── Backing Services (Redis, etc.)   --> Any service (DB, Cache, queue) should be treated as external service which can be changed easily.
            │      ├── Authorization & Authentication   --> Each service should be protected by Authorization and authentication.
            │      ├── API First    --> Design APIs first by OpenAPI/ SWaggerAPI so other team can uses APIs and develop their features.
            │      └── Logs --> Treat logging as event streams. Don't handle log files in the app. Instead use stdout/err. 
            │
            ├── Deployment Phase methodologies:
            │      ├── Dev/Prod Parity  --> Avoid "it-works-on-my-machine" situation, by using same codebase for all environment except configuration files for each environment.
            │      ├── Processes (stateless)    --> One or more stateless processes. No in-memory session or data, use Radis or DB to save it.
            │      ├── Concurrency  --> Each service able to handle multiple request in order it can be scale up when needed. Concurrent is a process when one CPU unit can works on multiple request one after another.
            │      └── Port Binding --> Each service has its own port to run on. Avoid use of external services like apache.
            │
            └── Post-Deployment Phase methodologies:
                    ├── Admin Processes --> Admin tasks (data migration, batch processing, data seeding) as additional process. exclude from app's run time.  
                    ├── Telemetry (Monitoring)  --> Monitor your applications through external tools to check health and other stuffs.
                    └── Disposability   --> Fast start up but graceful/ smooth shutdown. Application should close all connections and save all files before shutting down.

Configuration setting   ::
            yml or property file    :   (Lowest priority)
                        Create yml file to do configuration of application:
                            // application.yml
                            spring:
                                config:
                                    activate:
                                        on-profile: "dev"
                                profiles:
                                    active: "qa"

                            server:
                                port: 8080
                            
                            build:
                            version: "1.0"

                            # contact-info
                            accounts:
                            message:  "information about accounts API"
                            contactDetails:
                                name: "Krunal"
                                email: "k@gmail.com"
                            onCallSupport:
                                - (416)880-2323
                                - (416)880-2323

        Environment configuration   :   (Higher than yml configuration)
                    Providing configuration at Environment during runtime.

                    IDE ->  Click on "More run" -> Add Environment pathVariable

                    NOTE:
                        Seperate values by adding ";" 
                            build.version = 1.0 
                            turns into
                            BUILD_VERSION = 1.0

        Add to VM   :   (Higher priority than Environment variable)
                    ex.,
                        -Dspring.profiles.active=qa -Dbuild.version=5.5.5

        Add to CLI  :   (Highest Priority)
                    ex.,
                        --spring.profiles.active=prod --build.version=6.6.6.6

Show Configuration values at API end point  :
        Best Way    :
            Show all values in single API call:
                    Create yml file :
                        # contact-info
                            accounts:
                            message:  "information about accounts API"
                            contactDetails:
                                name: "Krunal"
                                email: "k@gmail.com"
                            onCallSupport:
                                - (416)880-2323
                    Create record file  :
                        step 1: add final variable to parameter of class as Record class will handle all getter and declaring final variable.
                        step 2: Since all properties are part of "accounts" root. use it on @ConfigurationProperties() on top of Record class:
                            @ConfigurationProperties(prefix = "accounts")
                                public record AccountsContactInfoDto(String message, Map<String, String> contactDetails, List<String> onCallSupport) {
                            }
                        Step 3: Enable configuration properties at Application file:
                            @EnableConfigurationProperties(value = {AccountsContactInfoDto.class})
                            @SpringBootApplication
                            class AccountApplication{...}
                        Step 4: Autowire record class and use it inside API Get method:
                            @Autowired
                            public AccountsContactInfoDto accountsContactInfoDto;

                            @GetMapping("/contact-details")
                            public ResponseEntity<AccountsContactInfoDto> getAccountContactInfo(){
                                return ResponseEntity
                                        .status(HttpStatus.OK)
                                        .body(this.accountsContactInfoDto);
                            }
        
        Access it by Property varible name  :
            Create a varibable and add @Value() on top of it. and use it inside API get method:
                ex.,    
                    @Value("${build.version}")
                    private String build_info;

            Or use Environment variable and access it thorugh that:
                ex.,
                    @Autowired
                    public Environment environment;

                    // use it like environment.getProperty("VARIABLE_NAME")
                    inside api method:
                        return environment.getProperty("JAVA_HOME");

Spring Cloud    ::
            Spring project often needs to restart when we update properties in order to view new changes...

            To overcome this drawback, we can use spring cloud.
            Spring cloud pulls configurations from centralized repo and all microservices pull configurations from Spring cloud in real time.

            Types of loading configuration  :  
                ->  native  :   Loads configuration files from given classpath.
                ->  git     :   Loads from git repo
                ->  svn     :   Loads from SVN repo

            Set-up Cloud server :
                Step 1  :   Create Spring configserver project. Make sure to add Spring cloud and Accurator (for monitor purposes) dependencies to the project.
                Step 2  :
                    -   Load maven changes
                    -   (optional)  refactor application file to .yml
                    -   Add cloud server name
                        ex.,
                            spring:
                                application:
                                    name: "configserver"
                    -   Add method to retrieve centralized configurations (native/ git/ SVN)
                        ex.,
                            // Native way:
                                spring:
                                profiles:
                                    active: native
                                cloud:
                                    config:
                                    server:
                                        native:
                                        search: "classpath:/config"

                            // Git way:
                                profiles:
                                    active: git
                                cloud:
                                    config:
                                    server:
                                        git:
                                        uri: "https://github.com/krunalpriyadarshi/encryptedConfig.git"     # Http link from github repo.
                                        default-label: main     # branch name where config files saved
                                        timeout: 5
                                        clone-on-start: true    # clone to Springcloud server to avoid unexpected errors
                                        force-pull: true        # force pull incase it does not pull from remote branch

                        NOTE: Add "classpath:/" as static text to local file location.
                Step 3  :
                    Add @EnableConfigServer annotation to the Application file to enable Cloud server.
                Step 4  :
                    Copy all configuration files from Microservices
                    NOTE: Name of the files will be "microserviceName + "-" + environmentName"
                        ex.,
                            accounts.yml
                            accounts-prod.yml
                            accounts-qa.yml

                            cards.yml
                            cards-prod.yml
                            cards-qa.yml

                    Remove unneccessory information like profile name, location, H2 database setup etc
                Step 5  :
                    Test cloud server
                    NOTE:   address of each request will be at "localhost:8071/" + microserviceName + "/" + "environmentName" 
                    ex.,
                        localhost:8071/accounts/native
                        localhost:8071/accounts/qa
                        localhost:8071/accounts/prod

                        localhost:8071/cards/native
                        localhost:8071/cards/qa
                        localhost:8071/cards/prod
                    
            Set-up Microservices    :
                Step 1  :   Update application.yml file by removing profile activation and import lines as it will be handle by cloud upon request. And info that is part of centralized configuration files.
                Step 2  :   Give application name
                            ex.,
                                spring:
                                    application:
                                        name: "accounts"
                                    
                            NOTE:   Spring cloud will match this name will configuration files so make sure to have same name.
                                Name on client side == Name on configuration file
                Step 3  :   Add dependency "Cloud client"
                            -   spring-cloud-version
                            -   dependency
                            -   dependencyManagement
                Step 4  :   import congiuration from centralized already
                            spring: 
                                config:
                                    import: "configserver:http://localhost:8071/"

                            NOTE:   "configserver:" is constant string needs to be added as prefix.

                            (optional)
                            give profile activation property:
                            spring:
                                profiles:
                                    active: "qa"

            Fetch all Latest configurations from Git without reload of microservice :
                Actuator api is going to fetch all details from Configuration by calling Management Refresh API.
                
                NOTE:
                    Configuration-server will fetch new details from Git if git set up is done.

                // Add Actuator dependency and enable Refresh API:
                    Step 1: Add dependency of Actuator
                        Valid go to "http://localhost:8080/actuator"
                    Step 2: Enable Management Refresh API for each microservice by adding this to configuration file.
                        management:
                            endpoints:
                                web:
                                    exposure:
                                        include: "refresh"
                    Step 3: Make sure all @ConfigurationProperties have Setter method inside as Spring will set these values when refresh API is called.
                    Step 4: Make Actuator Refresh API call to fetch all new configuration files from Configuration Server for rach microservice.
                        http://localhost:****/actuator/refresh

                        NOTE:
                            This Refresh API is POST method. Use POSTMAN to call this API.
                            It is not good practise to call APIs for each microservice as We might have 500 microservices for a project.

            Spring Cloud Bus    ::
                        Spring cloud Bus broadcast state change like configuration changes to all nodes of distributed service/ microservice with one request.

                        Earlier we need to call Actuator Refresh API for each microservice. 
                        With Cloud Bus, we need to call once BusRefresh API and it will broadcase to all distributed nodes of microservice to fetch new changes from Configuration-Server.

                        NOTE:
                            Install RabbitMQ from offical website 
                            Or 
                            Use Doocker install command.

                        Set-up:
                            Step 1: Add dependency of Cloud Bus and Actuator to all Microservices and Config-Server.
                                <dependency>
                                    <groupId>org.springframework.boot</groupId>
                                    <artifactId>spring-boot-starter-amqp</artifactId>
                                </dependency>
                            Step 2: Expose CloudBus Management API link
                                management:
                                    endpoints:
                                        web:
                                            exposure:
                                                include: busrefresh
                            Step 3: Set up RabbitMQ creds
                                spring:
                                    rabbitmq:
                                        host: "localhost"
                                        port: 5672
                                        username: "guest"
                                        password: "guest"
                            Step 4: Run RabbitMQ Docker image in Docker CLI.
                            Step 5: Run Config-server and then all microservice:
                                Run POST request --> localost://****/actuator/busrefresh

            Sprinig Cloud Monitor + GitHub WebHook  ::
                        To automate whole process, we can use Spring cloud monitor and GitHub WebHook.
                        AS we commit our changes to Github, all new changes will be broadcasted by it.

            Test With Docker    :
                        Create images of each component :
                            Step 1: Use Google Jib and create images for each microservice.
                            Step 2: Verify it exist by checking on docker desktop/ images or use command "docker images"
                            Step 3: use tag command to create relavent docker image to push it to docker hub.
                                docker tag eazybytes/accounts:s6 userName/accounts:s6

                                then, push it to hub by.,
                                docker push docker.io/krunal1k/accounts:s6

MySQL setup :
            step 1  :   Create MySQL container by calling below docker command.
                        ex.,
                             docker run -p 3308:3306 --name loandb -e MYSQL_ROOT_PASSWORD=root2 -e MYSQL_DATABASE=loansdb -d mysql

                             You are creating Database so make sure to remember the name of database.
                             Here mysql is Docker Image that will be downloaded from Docker Hub.

            Step 2  :   Setup MySQL client.
                        ->  Give Database Type  :   MySQL
                        ->  server address  :   localhost
                        ->  port    :   from Docker command on left side
                        ->  Use username/ password from given docker command.

            Step 3  :   Setup Microservice.
                        -> Remove H2 dependency
                        -> Add SQL dependency
                        -> application.yml file, add mysql creds and url to connect:
                            ex.,
                                  datasource:
                                        # syntex: jdbc:mysql://<host>:<port>/<database_name>
                                        url: jdbc:mysql://localhost:3308/loansdb
                                        username: root
                                        password: root2
                                    sql:
                                        init:
                                            mode: always
                                    jpa:
                                        show-sql: true      
            Step 4  :   Test application by calling APIs and check entry in MySQL Client.

            NOTE:
                If you delete contianer while application is running. 
                You just deleted database so when you try to execute POST APIs, it will result in database error.
                Also, application will create database on initial running phase so we need to re-run application in order to create database.

Traditional Load Balancer   :
            Mainly used for Monolithics and SOA based application as number of servers are fixed as manually Routing table needs to be created.

            Drawbacks
                -   High cost
                -   Manual setup for Routing table
                -   Complex configuration
                -   Can not be used for cloud native applications as their IPs changes with their instances

Readiness V/S Liveness Probe    :
    Readiness Probe -
        Question:   Am I ready to take request?
        purposes:   Checks if application is ready to accept traffic.
        Example :   DB is connected or not.
        Effect  :   Traffic won't be sent to App until it is marked as READY.
    Liveness Probe  -   
        Question:   Am I alive?
        purposes:   Checks if application is still alive.
        Example :   JVM is running, no deadlocks, no unresponsiveness.
        Effect  :   App will be restarted or killed if it is not ALIVE.

    Configuration steps -
        Step 1  -   Add Actuator dependency
        Step 2  -   expose health probe by setting true
        Step 3  -   enable health readiness and liveness

    NOTE:
        The Configuration Server (Spring Cloud Config Server) must start first, as all other containers rely on it for configuration.

        In application.yml, ensure the readiness and liveness checks for the Config Server are set up before dependent services (like Accounts, Loans, GatewayServer) start.

Service Discovery   :
            To over come drawbacks of Traditional Load Balancer, Service Discovery and Service registry were introduced.

            Service registry make entry or remove it, based on either server is created or removed.
            If multiple instances are created, load Balancer is placed.

            Types:
                -   Client-side Service Discovery
                -   Server-side Service Discovery

    Client-side Service Discovery   :
                Client side application is responsible to find and connect.
                where Service Registry will IPs of running instances and it might return list of IPs.

                Drawbacks
                    -   Client side application will work as load Balancer resulting in more responsibility on developers.
                    -   Custom algorithm needed for LB like Round-robin and Weighted Round-robin...
                
                Fix:
                    -   Use Server side Service Discovery.

                How it works:
                    -   Services will register themselves to Service Registry. A system can have multiple Service Registry and they will communicate with broadcast. So each service has to send details once to Service Registry and all Service Registries will hava data about new service instance.
                    -   If client application wants to send a request. It will first check valid cache and if it has entry, it will send request direct to that service instance.
                    -   Service Registry will invalid cache of client application if changes occured to service registry.
                 
Set-up Eureka Server    :
            Step 1  :   Add dependencies
                        -   Eureka server   :   To host as server which will work as Service Registry
                        -   Actuator        :   To get heartbeat of services in spam of 30 secounds
                        -   Config Client   :   To fetch configuration files from Centralized config-Server
            Step 2  :   Create Application.yml
                        -   Add server port and name
                            server:
                                port: 8070
                            spring:
                                application:
                                name: "eurekaserver"
                        -   Fetch details from Centralized configserver
                            spring:
                              config:
                                import: "optional:configserver:http://localhost:8071/"
                        -   Host endpoint of Eureka using management and health reading to check heartbeat of services
                            management:
                                endpoints:
                                    web:
                                    exposure:
                                        include: "*"
                                health:
                                    readiness-state:
                                    enabled: true
                                    liveness-state:
                                    enabled: true
                                endpoint:
                                    health:
                                    probes:
                                        enabled: true

Set-up Eureka Client on Services    :
            Step 1  :   Add dependency
                        -   Eureka client   -   To register service to Service Registry that this server is available to use.
                        eureka:
                            instance:
                                preferIpAddress: true
                        client:
                            fetchRegistry: true
                            registerWithEureka: true
                            serviceUrl:
                            defaultZone: http://localhost:8070/eureka/
            Step 2  :   Expose Service information thorugh Eureka
                        management:
                            info:
                                env:
                                    enabled:    true
                        info:
                            app:
                                name: "accounts"
                                description: "Eazy Bank Accounts Application"
                                version: "1.0.0"
            Step 3  :   Close server by calling "/actuator/shutdown" API 
                        management:
                              endpoint:
                                shutdown:
                                access: unrestricted
                        ex.,
                            Visit localhost:8080/actuator/shutdown --> to Stop current running microservice
            Step 4  :   Run application and Visit Eureka server to Validate Microservice is registed.
                        Call Shutdown api to stop executing microservice and validate on Eureka server that it is removed from list.

            NOTE:   Every 30 sec by default, Microservices will send Health status to ServiceRegistry- Eureka server.

Set-up Cross-site mapping   :
            NOTE:
                For microservices, it is hard to track IP address of services as new instances are being created once needed or deleted once no longer in use.
                And To automate that, OpenFeignClient dependency is being used.
                OpenFeign automatically bind allocated IP address to HttpRequest. 

            Step 1  :   Add OpenFeign dependency
            Step 2  :   Enable OpenFeignClient in Microservices
                        @EnableFeignClients
            Step 3  :   Create client Interface to consume other microservice Http Method.
                        @FeignClient(SPRING_APPLICATION_NAME)
                        interfave name{
                            @GetMapping("/api/fetch")
                            void method();
                        }
            Step 4  :   Now, consume api by calling above interface method.
                        -   service layer, add new method and logic
                        -   controller call repo's service layer method

Euroka's Self pre-servation mode to avoid network issue :
            In Euroka server, Server registry will maintain list of server instances.
            If one of server does not send HeartBeat, it means instance is either stopped or restarting. 
            Server Registry will not remove entry right away. 

            Instead, it will keep entry for 90s duration. 
            If heartbeat from same instance is not recieved, it will remove entry from Service Registry. 

API Gateways/ Edge server    :
            API Gateways are best for microservices as it's Simplifies communication, security, improved performance and management.

            Benefits    
            -   Single entry point: All client requests go through single gateway.
            -   Load balancing and failover
            -   Routing
            -   Security & Authentication
            -   Rate Limit
            -   Caching
            -   Monitor and logging

Spring Cloud Gateway    :
            - It is the preferred API Gateway for Spring applications.
            - Provides integration with circuit breakers (e.g., Resilience4j, Hystrix).
            - Supports service discovery (e.g., Eureka, Consul).
            - Built on Reactor Netty, making it non-blocking and reactive.

            Internal Architecture   :
                Clients         -   Send HTTPs requests to the gateway
                Gateway Handler -   Route request based on Routing configuration
                Predicate       -   Defined conditions (path, header, method) must be met for route to be selected.
                Pre Fillters    -   Business logic (authentication, auditing, logging, rate limiting)
                microservices   -   Handles a request 
                Post Fillters   -   Business logic (modifying response, logging)
                Gateway Handler -   send response back to client

Gateway server setup    :
            Step 1  :   Dependencies
                        -   actuator
                        -   spring-cloud-starter-config
                        -   spring-cloud-starter-gateway
                        -   netflix-eureka-client
            Step 2  :   application.yml file
                    # making port for gateway server
                    server:
                        port: 8072
                    
                    # fetch files from centralized configuration server 
                    spring:
                        application:
                            name: "gatewayserver"
                        config:
                            import: "optional:configserver:http://localhost:8071/"

                    # Enables dynamic route discovery via Eureka: and lower case matching is allowed accounts and ACCOUNTS will be treated same.
                    spring:
                      cloud:
                        gateway:
                        server:
                            webflux:
                            discovery:
                                locator:
                                enabled: true
                                lower-case-service-id: true

                    # Adding to eureka
                    eureka:
                        instance:
                            preferIpAddress: true
                        client:
                            fetchRegistry: true
                            registerWithEureka: true
                            serviceUrl:
                                defaultZone: http://localhost:8070/eureka/

                    # enable eureka and gateway 
                    management:
                        endpoints:
                            web:
                            exposure:
                                include: "*"
                        endpoint:
                            gateway:
                            enabled: true       # /actuator/gateway/routes will be exposed due to this setting.
                        info:
                            env:
                            enabled: true

RESILIENCE :
            Resilience is the ability of a system to overcome challenges and continue functioning smoothly.

            In microservices, sometimes a service may go down temporarily due to network issues or faults.

            Circuit Breaker pattern :
                        Resilience4j - the circuit breaker monitors the fault rate of requests to that service.

                        ex.,
                            When the fault rate crosses a certain threshold, the circuit breaker changes state from CLOSED to OPEN.
                            In the OPEN state, all requests to the faulty service fail immediately, preventing wasted resources and cascading failures.
                            After a configured cooldown period, the circuit breaker transitions to HALF_OPEN state to test if the service has recovered.
                            If the service responds successfully during this state, the circuit breaker closes the circuit again. Otherwise, it reopens and the cycle repeats.

Auto-Scaling    :
            Vertical Scaling    :
                Giving more resources (like CPU, Memory) of running instance to handle more requests.
                Example.,
                    An instance has 2 core CPU and 2 GB RAM. You scale up it to 4 cores and 8GB RAM to handle more requests.
                
                Use:
                ->  Useful for Thighly coupled applications
                ->  For Test and Dev instances
                
                Pros:
                ->   Easy to implement. No need to change Architecture of application.
                ->   Good for Monolithic applications or non-distributed applications.
                
                Cons:
                ->   Downtime   -   During scaling, application instance is temporarily unavailbale as restart needed.
                ->   Resource limit -   Sizing depends on Cloud service provider. As AWS does not provide more than certain RAM to each instance of running server.  
                ->   Cost inefficent    -   High computing processor charges are higher than regular.
            
            Horizontal Scaling  :
                Add or remove instance to handle traffic.
                Example.,
                    During high load scenario, we can clone existing instance of application and direct some traffic to new instance for better performance.

                Use:
                ->  Best for Microservices. 
                ->  Production environments where traffic is not constant.
                
                Pros:
                ->  Better Fault Tolerant   -   If one server dies, others handle load.
                ->  Support distributed services (microservices)
                ->  Auto-scaling    -   Cloud services automatically scale up or down to handle load.
                
                Cons:
                ->  Complex Architecture - To handle Load Balancer, distributed data
                ->  Not Optimal for single thread databases -   As database is locked by one instance. Adding more instance won't be helpful at all as process is not Concurrent for database like SQLite.







